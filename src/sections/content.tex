%! Author = jasmincapka
%! Date = 31.03.22

This discussion focuses on the thesis of~\cite{vredenburgh} that the discussion of algorithmic bias should not focus on fairness, but on justice.
In this context, algorithmic bias means the ``deviation of an algorithm’s performance from what is required by some standard"~\parencite[][1]{vredenburgh} and is treated in a moral sense.
In that it signifies ``the encoding of wrongfully discriminatory social patterns into an algorithm"~\parencite[][2]{vredenburgh}.

\section*{Definition of ``justice" and ``fairness" }

According to~\cite[][3, 11--12]{vredenburgh}, justice is the term for the moral norms that affect our most fundamental institutions, for example norms of distribution and respect.
This means, justice prescribes moral commitments about how these important societal institutions from legal, political or economical field should be treating people.
Moral norms or standards determine the chances, obligations, entitlements or burdens, people might have in life.
Additionally, they create a certain perception of the term justice and shape people's life.

An example for this would be the german law ``BaföG" (from its German acronym Bundesausbildungsförderungsgesetz, German Federal Law on Training and Education Promotion).
It regulates all available federal student grants and loans in Germany.
The law was issued by the German government, a political institution, with the underlying moral norm of equal opportunity for education regardless of individual background.
It has a high impact, especially on young people in Germany, and presents the opportunity of good education.
Consequently, this also fosters awareness among people, that everyone deserves the chance to receive the same education regardless of monetary factors.

Fairness, according to~\cite[][3, 13]{vredenburgh}, is the term for whether the claims of similar individuals are considered equally.
It is about the respect of equal claims in proportion to the different strengths of individual claims.
Therefore, fairness is based on the moral principle of equality of people.

Here, the example of ``BaföG" can again be brought up.
In that case, fairness would mean that everyone receives student grants and loans with respect to the strength of this claim.
The strength in this case is given by the individual background and monetary factors of people as defined by justice.

Overall, fairness is one, but not the only, value of justice and a major moral concept when it comes to justice and Artificial Intelligence (AI).~\parencite[][11, 13]{vredenburgh}

\section*{Argumentation for thesis}

~\cite{vredenburgh} starts with her prior conclusions that different technical interventions can lead to different values of justice and that a trade-off between fairness and other values of justice is possible~\parencite[][18]{vredenburgh}.
Nevertheless, there is not always a trade-off between those two, because in case of serious injustice, fairness is of no value.
Fairness is dependent on the other values of justice to determine which cases are morally alike and the question is whether claims are respected in regard to what they are fixed to be by other values of justice~\parencite[][18, 19]{vredenburgh}.

This leads to the thesis of~\cite{vredenburgh}, that the important dimension for moral evaluation of algorithms is justice, not fairness.
Her claim is that "If the contexts in which AI is designed and deployed are seriously unjust, then one must prioritize other values of justice over fairness"~\parencite[][19]{vredenburgh}.

The first reason for the thesis is that fairness does not exist without justice~\parencite[][19]{vredenburgh}.
The value of fairness can only emerge if it is backed up with just institutions.
Only when people have claims that are legitimate, fairness can be an important value.

The second argument is that fair decisions may increase injustice if for example they rely on biased input~\parencite[][19]{vredenburgh}.
In case of a trade-off the focus should lie on whether a decision process compounds injustice as this is of higher priority than fairness.

\section*{Policy recommendations}

~\cite{vredenburgh} makes the following five recommendations for just AI:

The first recommendation is to recognize the underlying value of justice behind the policy goal for regulation.
The development and deployment of AI should be controlled by this value and not by data availability.

Furthermore, she suggests to ``de-couple decision processes"~\parencite[][22]{vredenburgh}.
As injustice can be increased among several decision processes, the same AI system should not be used for a large class of decisions.

Thirdly, structural injustice should be modelled to incorporate information about injustice in the decision process.
This can be used to understand whether included features might support injustice and where and how to intervene against injustice.

Another recommendation focuses on ``better data"~\parencite[][24]{vredenburgh}.
The aim is to increase the quality of data to build more accurate and robust models.

Lastly, the advice is to use more weighted lotteries instead of decision thresholds having a focus on fairness.
Randomness through weighted lotteries increases fairness for indivisible goods.

\section*{Importance of recommendation}

In my opinion, the forth recommendation ``better data" is the most important one.
Even though an enhanced data generation or acquisition process might be difficult to implement and need some time until one can profit from it, better data also solves other problems:

Better data would grant much more insight in decision processes, for example regarding justice, fairness or bias.
When having better data, the challenge of data availability in the first recommendation could be eased.
Regarding the second suggestion, if the input data were better, the AI could be used for more decision processes without compounding injustice.
Additional, better data would lead to more options to model injustice in recommendation three.
For the last advice, data is needed to properly model the strength of claims for a weighted lottery.

Therefore, using better data supports all other recommendations as well and is a crucial component in developing AI, which is why I chose this recommendation.

\section*{Recommendation in practice}

Coming back to the example of ``BaföG", the underlying moral norm of equal opportunity for education regardless of individual background in itself represents justice.
But it is implemented in a way, that the strict application process through predefined forms leaves no space for the individual consideration of special cases.
Therefore, in practice, it is not entirely just in that it does not rate all young people in a way that would give them equal opportunities and does not entirely follow its moral value
Nevertheless, this still leads to the application process being fair in that it respects the claims of individual students equally in proportion to their strength, only these strengths being defined in an unjust way.

Currently, a person that owns half a house would be considered to have a good monetary background and no strong claim for funding.
Putting this into the perspective that the person inherited half the house her family is living in because her father died at young age and does not get any monetary benefits from this, creates injustice.
According to the moral norm the person should have a claim as strong as someone without owning part of a house.
Inheritance is a general problem with ``BaföG" as the process is currently not able to detect whether someone with apparently strong monetary background might still have strong claims for funding.

If the government were to collect more and better data about young people and their individual situations, the AI deciding about the funding could be improved.
Surveys that do not only fit into the current process but also consider further features could further develop the decision process and maybe even help detect further injustice.
Constant improvement and adaption of data generation is needed to correctly implement the moral norm of equal opportunity for education and enhance the justice of the decision processes of ``BaföG".