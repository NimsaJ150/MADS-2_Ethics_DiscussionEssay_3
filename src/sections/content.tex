%! Author = jasmincapka
%! Date = 31.03.22

This discussion focuses on the thesis of~\cite{vredenburgh} that the discussion of algorithmic bias should not focus on fairness, but on justice.
In this context, algorithmic bias means the ``deviation of an algorithm’s performance from what is required by some standard"~\parencite[][1]{vredenburgh} and is treated in a moral sense.
In that it signifies ``the encoding of wrongfully discriminatory social patterns into an algorithm"~\parencite[][2]{vredenburgh}.

\section*{Definition of ``justice" and ``fairness" }

According to~\cite[3, 11--12]{vredenburgh}, justice is the term for the moral norms that affect our most fundamental institutions, for example norms of distribution and respect.
This means, justice prescribes moral commitments about how these important societal institutions from legal, political or economical field should be treating people.
Moral norms or standards determine the chances, obligations, entitlements or burdens, people might have in life.
Additionally, they create a certain perception of the term justice and shape people's life.

An example for this would be the german law ``BaföG" (from its German acronym Bundesausbildungsförderungsgesetz, German Federal Law on Training and Education Promotion).
It regulates all available federal student grants and loans in Germany.
The law was issued by the German government, a political institution, with the underlying moral norm of equal opportunity for education regardless of individual background.
It has a high impact, especially on young people in Germany, and presents the opportunity of good education to them.
Consequently, this also fosters awareness among people, that everyone deserves the chance to receive the same education regardless of monetary factors.

Fairness, according to~\cite[3, 13]{vredenburgh}, in contrast is one, but not the only value of justice.
Fairness is the term for whether the claims of similar individuals are considered equally.
It is about the respect of equal claims in proportion to the different strengths of individual claims.
Therefore, fairness is based on the moral principle of equality of people.
- Thus, resources are distributed in a fair way, when people's claims are respected with regard to their strength.

Here, the example of ``BaföG" can again be brought up.
In that case, fairness would mean that everyone receives student grants and loans with respect to the strength of this claim.
The strength in this case is given by the individual background and monetary factors of people as defined by justice.

- Overall, fairness is one standard of justice and a major moral concept when it comes to justice and Artificial Intelligence (AI).~\parencite[][11, 13]{vredenburgh}

\section*{Argumentation for thesis}

~\cite{vredenburgh} starts with the prior conclusions that different technical interventions can lead to different values of justice and that a trade-off between fairness and other values of justice is possible~\parencite[][18]{vredenburgh}.
Nevertheless, there is not always a trade-off between those two, because in case of serious injustice, fairness is of no value.
Fairness is dependent on the other values of justice to determine which cases are morally alike and the question is whether claims are respected in regard to what they are fixed to be by other values of justice~\parencite[][18, 19]{vredenburgh}.

This leads to the thesis of~\cite{vredenburgh}, that the important dimension for moral evaluation of algorithms is justice, not fairness.
Her claim is that "If the contexts in which AI is designed and deployed are seriously unjust, then one must prioritize other values of justice over fairness"~\parencite[][19]{vredenburgh}.

The first reason for the thesis is that fairness does not exist without justice~\parencite[][19]{vredenburgh}.
The value of fairness can only emerge if it is backed up with just institutions.
Only when people have claims that are legitimate, fairness can be an important value.

The second argument is that fair decisions may increase injustice if for example they rely on biased input~\parencite[][19]{vredenburgh}.
In case of a trade-off the focus should lie on whether a decision process compounds injustice as this is of higher priority than fairness.

\section*{focus on the policy recommendations she makes for just AI}

"Take a values-first approach to bias interventions"~\parencite[][20]{vredenburgh}
- recognize the underlying value behind the goal of mitigating a given bias
- different values of justice support different standards to measure bias in the system, and support different intervention
- AI development and deployment should be driven by values, not by data availability

"De-couple decision processes"~\parencite[][22]{vredenburgh}
- AI can compound injustice across decision processes
- strong reasons of justice to avoid using the same AI system for a large class of decisions

- Drawbacks:
  - "reduces the accuracy of decisions, by limiting the input data for building AI systems"
  - "in many cases data are used to make efficient decisions that are better than choosing at random, not highly accurate decisions"

"Model structural injustice"~\parencite[][23]{vredenburgh}
- "include information about structural injustice in the decision process, especially for decision-makers that ought to advance justice"
- be cautious about included features that might support injustice
- understand where and how to intervene against injustice

"Better data"~\parencite[][24]{vredenburgh}
- "improve data quality"
- "Increasing data quality will produce more accurate and robust models"

"Replace decision thresholds with more (weighted) lotteries"~\parencite[][24]{vredenburgh}
- focus on fairness
- "randomness offers another technical lever to increase fairness"
- "claim relies on the definition of fairness as the satisfaction of claims in proportion to their relative strength"
- "fairness requires weighted lotteries for indivisible goods – and, more generally, that claims be satisfied in proportion to their strength"


\section*{Which of these recommendations do you find the most important and why}

better data


difficult to implement, needs time
data privacy concerns


also solves other problems:
- much more insight
  - racism
  - justice
  - fairness
  - bias


1 keine Abwägung zwischen value und data availability
2 no more need to decouple decision processes
3 more options to model injustice
4
5 get data about claims, prio of justice over fairness




\section*{Illustrate what that recommendation would mean in practice by using your own example.}

Coming back to the example of ``BaföG", the underlying moral norm of equal opportunity for education regardless of individual background in itself represents justice.
But it is implemented in a way, that the strict application process through predefined forms leaves no space for the individual consideration of special cases.
Therefore, in practice, it is not entirely just in that it does not rate all young people in a way that would give them equal opportunities.
This means, ``BaföG" does not entirely follow its norm for total equality for chance of education.
Nevertheless, this still leads to the application process being fair in that it respects the claims of individual students equally in proportion to their strength, only these strengths being defined in an unjust way.

- Ausgangslage
  - BaföG is not 100 percent just

  - [Einzelfallbehandlung] is not fully implemented as a norm for total equality for chance of education
  - However, with BaföG, the justificial norm is thoroughly implemented, meaning it might not be just but it is fair due to the explicit implementation

- Übergang
  - Datengenerierung
  - Datenbeschaffung

- Resultat

