%! Author = jasmincapka
%! Date = 31.03.22

This essay examines the thesis of~\cite{vredenburgh} that the discussion of algorithmic bias should not focus on fairness, but on justice.

\section*{Definition of ``justice" and ``fairness" }

According to~\cite[][3, 11--12]{vredenburgh}, justice is the term for the moral norms that affect fundamental institutions.
This means, justice prescribes moral commitments about how these important societal institutions should be treating people.
Moral norms or standards determine the chances, obligations, entitlements or burdens people might have in life.
Additionally, they create a certain perception of the term justice and shape people's lives.

An example for this would be the German law ``BAföG" which regulates all available federal student grants and loans in Germany.
The law was issued by the German government, a political institution, with the underlying moral norm of equal opportunity for education regardless of monetary background.
It has a high impact as it presents the opportunity of good education.

Fairness, according to~\cite[][3, 13]{vredenburgh}, is based on the moral principle of equality of people as it promotes equal consideration of claims in proportion to the different strengths of individual claims.

In the ``BAföG" example, fairness would mean every student receives grants and loans with respect to the strength of their claims.
The strength of a claim is given by the individual monetary background of people as defined by justice.

\section*{Argumentation for thesis}

~\cite{vredenburgh} argues that different technical interventions lead to different values of justice and that a trade-off between fairness and other standards of justice is possible~\parencite[][18]{vredenburgh}.
Nevertheless, there is not always a trade-off between the two, because in case of serious injustice, fairness is of no value.
Fairness is dependent on other standards of justice to determine morally alike cases and the question is whether claims are respected in regard to what they are fixed to be by other values of justice~\parencite[][18, 19]{vredenburgh}.

This leads to the thesis of~\cite{vredenburgh}, that the important dimension for moral evaluation of algorithms is justice, not fairness.
Her claim is that ``If the contexts in which AI is designed and deployed are seriously unjust, then one must prioritize other values of justice over fairness"~\parencite[][19]{vredenburgh}.

The first reason for this thesis is that fairness does not exist without justice~\parencite[][19]{vredenburgh}.
The value of fairness can only emerge if it is backed up with just institutions.
Only when people have legitimate claims, fairness can be an important value.

The second argument is that fair decisions may increase injustice if for example they rely on biased input~\parencite[][19]{vredenburgh}.
In case of a trade-off, the focus should lie on the detection of injustice in a decision process as this is of higher priority than fairness.

\section*{Policy recommendations}

\cite{vredenburgh} makes five recommendations for just AI:

The first recommendation is to recognize the underlying value of justice behind the policy goal for regulation.
The development of AI should be controlled by this value and not by data availability.

Furthermore, she suggests to ``de-couple decision processes"~\parencite[][22]{vredenburgh}.
As injustice can be increased amongst several decision processes, the same AI system should not be used for a large class of decisions.

Thirdly, structural injustice should be modelled to incorporate information about injustice in the decision process.
This can be used to understand whether included features might support injustice as well as where and how to intervene.

Another recommendation focuses on ``better data"~\parencite[][24]{vredenburgh}.
The aim is to increase the data quality to build more accurate and robust models.

Lastly, the advice is to use more weighted lotteries instead of decision thresholds having a focus on fairness.
Randomness through weighted lotteries increases fairness for indivisible goods.

\section*{Importance of recommendation}

In my opinion, the forth recommendation ``better data" is the most important one.
Even though an enhanced data generation or acquisition process might be difficult to implement and need some time until it pays off, better data also solves other problems:

Better data would grant much more insight in decision processes, for example regarding justice, fairness or bias.
When having better data, the challenge of data availability in the first recommendation could be eased.
Regarding the second suggestion, the AI could be used for more decision processes without compounding injustice.
Additionally, better data would lead to more options to model injustice with respect to the third recommendation.
As for the last point made, data is needed to properly model the strength of claims for a weighted lottery.

Therefore, better data supports all other recommendations and it is a crucial component in developing AI.

\section*{Recommendation in practice}

Coming back to the example of ``BAföG", the underlying moral norm of equal opportunity for education regardless of monetary background in itself represents justice.
But it is implemented so that the strict application process through predefined forms leaves no space for the individual consideration for cases of hardship.
Therefore, in practice, it is not just in that it does not evaluate all students in a way that would give them equal opportunities.
Nevertheless, this still leads to the application process being fair in that it respects the claims of individual students equally in proportion to their strength, only these strengths being defined in an unjust way.

Currently, a person owning half a house would be considered having a good monetary background without strong claim for funding.
Putting this into perspective that the person inherited half the house her family is living in, not receiving any monetary benefits, creates injustice.
According to the moral norm the person should have as strong a funding claim as someone without ground property.
Inheritance is a general problem with ``BAföG" as the process is not considering the actual benefit of a certain monetary background.

If the government were to collect more and better data about young people and their individual situations, the decision process could be improved by also introducing well-developed AI.
Surveys could consider additional features to further develop the decision process and maybe even help detect further injustice.
Constant improvement and adaption of data generation is needed to correctly implement the moral norm of equal opportunity for education and enhance the justice of the decision processes of ``BAföG".